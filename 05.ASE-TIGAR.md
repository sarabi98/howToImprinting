``` ruby
#!/bin/bash
#
#----------------------------------------------------------------
# running a multiple independent jobs
#----------------------------------------------------------------
#
#  Defining options for slurm how to run
#----------------------------------------------------------------
#
#SBATCH --job-name=aseC1
#SBATCH --output=ASEC1.log
#        %A and %a are placeholders for the jobid and taskid, resp.
#
#Number of CPU cores to use within one node
#SBATCH -c 5
#
#Define the number of hours the job should run. 
#Maximum runtime is limited to 10 days, ie. 240 hours
#SBATCH --time=240:00:00

#SBATCH --mail-user=madamega@ist.ac.at
#SBATCH --mail-type=ALL

#SBATCH --array=1-11 
#IMPORTANT NUMBER OF FILES TO BE PROCESSED
#number of files in a directory: ls -1 | wc -l
#for this job: ls /nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/F1C1KS/*1.fastq -1 | wc -l = 11

#Define the amount of RAM used by your job in GigaBytes
#In shared memory applications this is shared among multiple CPUs
#SBATCH --mem=99G
#
#Do not requeue the job in the case it fails.
#SBATCH --no-requeue
#
#Do not export the local environment to the compute nodes
#SBATCH --export=NONE
unset SLURM_EXPORT_ENV

#module load 
module load java
module load samtools
module load ase_tigar/20210809

#IMPORTANT DO NOT LOAD JAVA 
# Search all the fastq files from the "data" directory and generate the array
file=$(ls /nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/aligment_vcf/bowtieAlignC1/*.sam | sed -n ${SLURM_ARRAY_TASK_ID}p)

dir='/nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/aligment_vcf/'

base=$(basename $file ".sam")
echo ${base}.sam
echo 'working on:'${SLURM_ARRAY_TASK_ID}

#just C1, add C2 on another script
java -jar /mnt/nfs/clustersw/shared/ase_tigar/20210809/ASE-TIGAR.jar --thread_num 8 ${dir}merged/crossKAZxSIN_refMrna.fa ${dir}bowtieAlignC1/${base}.sam --is_paired --alpha_zero 0.1 outputC1/${base}_ASE.txt
```
