Run ASE-TIGAR for C1
``` ruby
#!/bin/bash
#
#----------------------------------------------------------------
# running a multiple independent jobs
#----------------------------------------------------------------
#
#  Defining options for slurm how to run
#----------------------------------------------------------------
#
#SBATCH --job-name=aseC1
#SBATCH --output=ASEC1.log
#        %A and %a are placeholders for the jobid and taskid, resp.
#
#Number of CPU cores to use within one node
#SBATCH -c 5
#
#Define the number of hours the job should run. 
#Maximum runtime is limited to 10 days, ie. 240 hours
#SBATCH --time=240:00:00

#SBATCH --mail-user=madamega@ist.ac.at
#SBATCH --mail-type=ALL

#SBATCH --array=1-11 
#IMPORTANT NUMBER OF FILES TO BE PROCESSED
#number of files in a directory: ls -1 | wc -l
#for this job: ls /nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/F1C1KS/*1.fastq -1 | wc -l = 11

#Define the amount of RAM used by your job in GigaBytes
#In shared memory applications this is shared among multiple CPUs
#SBATCH --mem=99G
#
#Do not requeue the job in the case it fails.
#SBATCH --no-requeue
#
#Do not export the local environment to the compute nodes
#SBATCH --export=NONE
unset SLURM_EXPORT_ENV

#module load 
module load java
module load samtools
module load ase_tigar/20210809

#IMPORTANT DO NOT LOAD JAVA 
# Search all the fastq files from the "data" directory and generate the array
file=$(ls /nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/aligment_vcf/bowtieAlignC1/*.sam | sed -n ${SLURM_ARRAY_TASK_ID}p)

dir='/nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/aligment_vcf/'

base=$(basename $file ".sam")
echo ${base}.sam
echo 'working on:'${SLURM_ARRAY_TASK_ID}

#just C1, add C2 on another script
java -jar /mnt/nfs/clustersw/shared/ase_tigar/20210809/ASE-TIGAR.jar --thread_num 8 ${dir}merged/crossKAZxSIN_refMrna.fa ${dir}bowtieAlignC1/${base}.sam --is_paired --alpha_zero 0.1 outputC1/${base}_ASE.txt
```
Run ASE-TIGAR for C2
``` ruby
#!/bin/bash
#
#----------------------------------------------------------------
# running a multiple independent jobs
#----------------------------------------------------------------
#
#  Defining options for slurm how to run
#----------------------------------------------------------------
#
#SBATCH --job-name=aseC2
#SBATCH --output=ASEC2.log
#        %A and %a are placeholders for the jobid and taskid, resp.
#
#Number of CPU cores to use within one node
#SBATCH -c 5
#
#Define the number of hours the job should run. 
#Maximum runtime is limited to 10 days, ie. 240 hours
#SBATCH --time=240:00:00

#SBATCH --mail-user=madamega@ist.ac.at
#SBATCH --mail-type=ALL

#SBATCH --array=1-13 
#IMPORTANT NUMBER OF FILES TO BE PROCESSED
#number of files in a directory: ls -1 | wc -l
#for this job: ls /nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/F1C1KS/*1.fastq -1 | wc -l = 11

#Define the amount of RAM used by your job in GigaBytes
#In shared memory applications this is shared among multiple CPUs
#SBATCH --mem=99G
#
#Do not requeue the job in the case it fails.
#SBATCH --no-requeue
#
#Do not export the local environment to the compute nodes
#SBATCH --export=NONE
unset SLURM_EXPORT_ENV

#module load java
#module load java
module load samtools
module load ase_tigar/20210809

#IMPORTANT DO NOT LOAD JAVA 
# Search all the fastq files from the "data" directory and generate the array
file=$(ls /nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/aligment_vcf/bowtieAlignC2/*.sam | sed -n ${SLURM_ARRAY_TASK_ID}p)

dir='/nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/aligment_vcf/'

base=$(basename $file ".sam")
echo ${base}.sam
echo 'working on:'${SLURM_ARRAY_TASK_ID}

#just C1, add C2 on another script
java -jar /mnt/nfs/clustersw/shared/ase_tigar/20210809/ASE-TIGAR.jar --thread_num 8 ${dir}merged/crossSINxKAZ_refMrna.fa ${dir}bowtieAlignC2/${base}.sam --is_paired --alpha_zero 0.1 outputC2/${base}_ASE.txt
```
Parental samples
``` ruby
#!/bin/bash
#
#----------------------------------------------------------------
# running a multiple independent jobs
#----------------------------------------------------------------
#
#  Defining options for slurm how to run
#----------------------------------------------------------------
#
#SBATCH --job-name=aseSC
#SBATCH --output=ASESC1.log
#        %A and %a are placeholders for the jobid and taskid, resp.
#
#Number of CPU cores to use within one node
#SBATCH -c 5
#
#Define the number of hours the job should run. 
#Maximum runtime is limited to 10 days, ie. 240 hours
#SBATCH --time=240:00:00

#SBATCH --mail-user=madamega@ist.ac.at
#SBATCH --mail-type=ALL

#SBATCH --array=0-10 
#IMPORTANT NUMBER OF FILES TO BE PROCESSED
#number of files in a directory: ls -1 | wc -l
#for this job: ls /nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/F1C1KS/*1.fastq -1 | wc -l = 11

#Define the amount of RAM used by your job in GigaBytes
#In shared memory applications this is shared among multiple CPUs
#SBATCH --mem=99G
#
#Do not requeue the job in the case it fails.
#SBATCH --no-requeue
#
#Do not export the local environment to the compute nodes
#SBATCH --export=NONE
unset SLURM_EXPORT_ENV

#module load java
module load java
module load samtools
module load ase_tigar/20210809

#IMPORTANT DO NOT LOAD JAVA 
# Search all the fastq files from the "data" directory and generate the array
files=('97661_P_KAZ_F' '39873_P_KAZ_M' '39874_P_KAZ_M' '39875_P_KAZ_F' '39876_P_KAZ_F' '39869_P_SIN_M' '39870_P_SIN_M' '39871_P_SIN_F' '39872_P_SIN_F' '97660_P_SIN_M')
#files=("39871_P_SIN_F") #"97661_P_KAZ_F" "39873_P_KAZ_M" 
file=${files[$SLURM_ARRAY_TASK_ID]}

dir='/nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/version3_betterVCF/aligment_vcf/'


echo 'working on:'${SLURM_ARRAY_TASK_ID}
echo $file

#just C1, add C2 on another script
java -jar /mnt/nfs/clustersw/shared/ase_tigar/20210809/ASE-TIGAR.jar --thread_num 8 ${dir}merged/crossKAZxSIN_refMrna.fa ${dir}sanityCheck/${file}.sam --is_paired --alpha_zero 0.1 outputSC/${file}_ASE.txt
```
Output files:

/nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/version3_betterVCF/outputC1/

/nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/version3_betterVCF/outputC2/

/nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/version3_betterVCF/outputSC/
