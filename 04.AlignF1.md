Following Gemma's pipeline

Prerequisite in the same folder:

merge_pat_mat_fasta.pl

## Merge both transcriptomes 

``` ruby
## 2. ESTIMATE ASE
## 2.1. Prepare cDNA reference sequences and merge them in one FASTA file

dirin='/nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/VCF_DP_better/'
dirout='merged/'
chmod +x ./merge_pat_mat_fasta.pl
./merge_pat_mat_fasta.pl ${dirin}sinPWB_SNPs.genrec.fa ${dirin}kazPWB_SNPs.genrec.fa > ${dirout}crossKAZxSIN_refMrna.fa
./merge_pat_mat_fasta.pl ${dirin}kazPWB_SNPs.genrec.fa ${dirin}sinPWB_SNPs.genrec.fa > ${dirout}crossSINxKAZ_refMrna.fa

## 2.2. Build bowtie2 index

dirin='merged/'
dirout='bowtieIndex/'

module load bowtie2


bowtie2-build ${dirin}crossKAZxSIN_refMrna.fa ${dirout}crossKAZxSIN_refMrna
bowtie2-build ${dirin}crossSINxKAZ_refMrna.fa ${dirout}crossSINxKAZ_refMrna
```

## Align F1 samples to new merged transctiptomes

Array job

```ruby
#!/bin/bash
#
#----------------------------------------------------------------
# running a multiple independent jobs
#----------------------------------------------------------------
#
#  Defining options for slurm how to run
#----------------------------------------------------------------
#
#SBATCH --job-name=bowtieArray
#SBATCH --output=bowtieArray.log
#        %A and %a are placeholders for the jobid and taskid, resp.
#
#Number of CPU cores to use within one node
#SBATCH -c 5
#
#Define the number of hours the job should run. 
#Maximum runtime is limited to 10 days, ie. 240 hours
#SBATCH --time=240:00:00

#SBATCH --array=1-11 #IMPORTANT NUMBER OF FILES TO BE PROCESSED
#number of files in a directory: ls -1 | wc -l
#for this job: ls /nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/F1C1KS/*1.fastq -1 | wc -l
#11
#Define the amount of RAM used by your job in GigaBytes
#In shared memory applications this is shared among multiple CPUs
#SBATCH --mem=99G
#
#Do not requeue the job in the case it fails.
#SBATCH --no-requeue
#
#Do not export the local environment to the compute nodes
#SBATCH --export=NONE
unset SLURM_EXPORT_ENV

module load bowtie2

# Search all the fastq files from the "data" directory and generate the array
file=$(ls /nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/F1C1KS/*1.fastq | sed -n ${SLURM_ARRAY_TASK_ID}p)

dir="/nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/F1C1KS"
base=$(basename $file "_1.fastq")
echo ${dir}/${base%%.*}.1.fastq
echo 'working on:'${SLURM_ARRAY_TASK_ID}

bowtie2 -p 8 -X 1000 -k 100 --very-sensitive -x bowtieIndex/crossKAZxSIN_refMrna -1 ${dir}/${base%%.*}.1.fastq -2 ${dir}/${base%%.*}.2.fastq -S bowtieAlignC1/${base%%.*}.sam

```

Repeat for C2 


Notice change of reference to merged transcriptome
```
#!/bin/bash
#
#----------------------------------------------------------------
# running a multiple independent jobs
#----------------------------------------------------------------
#
#  Defining options for slurm how to run
#----------------------------------------------------------------
#
#SBATCH --job-name=bowtieArrayC2
#SBATCH --output=bowtieArrayC2.log
#        %A and %a are placeholders for the jobid and taskid, resp.
#
#Number of CPU cores to use within one node
#SBATCH -c 5
#
#Define the number of hours the job should run. 
#Maximum runtime is limited to 10 days, ie. 240 hours
#SBATCH --time=240:00:00

#SBATCH --array=1-13 #IMPORTANT NUMBER OF FILES TO BE PROCESSED
#number of files in a directory: ls -1 | wc -l
#for this job: ls /nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/F1C2SK/*1.fastq -1 | wc -l
#13
#Define the amount of RAM used by your job in GigaBytes
#In shared memory applications this is shared among multiple CPUs
#SBATCH --mem=99G
#
#Do not requeue the job in the case it fails.
#SBATCH --no-requeue
#
#Do not export the local environment to the compute nodes
#SBATCH --export=NONE
unset SLURM_EXPORT_ENV

module load bowtie2

# Search all the fastq files from the "data" directory and generate the array
file=$(ls /nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/F1C2SK/*1.fastq | sed -n ${SLURM_ARRAY_TASK_ID}p)

dir="/nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/F1C2SK"
base=$(basename $file "_1.fastq")
echo ${dir}/${base%%.*}.1.fastq
echo 'working on:'${SLURM_ARRAY_TASK_ID}

bowtie2 -p 8 -X 1000 -k 100 --very-sensitive -x bowtieIndex/crossSINxKAZ_refMrna -1 ${dir}/${base%%.*}.1.fastq -2 ${dir}/${base%%.*}.2.fastq -S bowtieAlignC2/${base%%.*}.sam
```
Parental samples, aligned to first merged transcriptome

```
#!/bin/bash
#
#----------------------------------------------------------------
# running a multiple independent jobs
#----------------------------------------------------------------
#
#  Defining options for slurm how to run
#----------------------------------------------------------------
#
#SBATCH --job-name=SC_C1
#SBATCH --output=SC_C1.log
#        %A and %a are placeholders for the jobid and taskid, resp.
#
#Number of CPU cores to use within one node
#SBATCH -c 5
#
#Define the number of hours the job should run. 
#Maximum runtime is limited to 10 days, ie. 240 hours
#SBATCH --time=240:00:00

#SBATCH --array=0-10 #IMPORTANT NUMBER OF FILES TO BE PROCESSED
#number of files in a directory: ls -1 | wc -l
#for this job: ls /nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/F1C1KS/*1.fastq -1 | wc -l
#11
#Define the amount of RAM used by your job in GigaBytes
#In shared memory applications this is shared among multiple CPUs
#SBATCH --mem=99G
#
#Do not requeue the job in the case it fails.
#SBATCH --no-requeue
#
#Do not export the local environment to the compute nodes
#SBATCH --export=NONE
unset SLURM_EXPORT_ENV

module load bowtie2

# Search all the fastq files from the "data" directory and generate the array
files=('97661_P_KAZ_F' '39873_P_KAZ_M' '39874_P_KAZ_M' '39875_P_KAZ_F' '39876_P_KAZ_F' '39869_P_SIN_M' '39870_P_SIN_M' '39871_P_SIN_F' '39872_P_SIN_F' '97660_P_SIN_M')
file=${files[$SLURM_ARRAY_TASK_ID]}

dir="/nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/parents/"
echo ${dir}${file}.1.fastq.gz
echo 'working on:'${SLURM_ARRAY_TASK_ID}

bowtie2 -p 8 -X 1000 -k 100 --very-sensitive -x bowtieIndex/crossKAZxSIN_refMrna -1 ${dir}${file}.1.fastq.gz -2 ${dir}${file}.2.fastq.gz -S sanityCheck/${file}.sam
```

path to folder: /nfs/scistore18/vicosgrp/madamega/artemiaImprinting/analysis/version3_betterVCF/aligment_vcf/

